---
layout: default
title: "Explainable AI Resources"
---

# Explainable AI (XAI) Resources

Understanding how and why models make predictions is crucial—especially in high–stakes applications. This page curates essential tools and resources for achieving model explainability.

## Key Python Packages
- **SHAP (SHapley Additive exPlanations):**  
  Uses game–theoretic methods to assign contribution values to each feature for an individual prediction.  
  [GitHub Repository](https://github.com/slundberg/shap)

- **LIME (Local Interpretable Model–Agnostic Explanations):**  
  Provides local approximations of complex models to explain individual predictions.  
  [GitHub Repository](https://github.com/marcotcr/lime)

- **InterpretML:**  
  Offers both inherently interpretable (glass-box) models and model–agnostic explanation methods in a user–friendly interface.  
  [GitHub Repository](https://github.com/interpretml/interpret)

- **Alibi & ELI5:**  
  - **Alibi:** Supports counterfactual explanations and feature attribution methods.  
    [GitHub Repository](https://github.com/SeldonIO/alibi)
  - **ELI5:** Helps debug and interpret model predictions.  
    [GitHub Repository](https://github.com/TeamHG-Memex/eli5)

- **Exemplary Explainable Clustering Approaches:**  
  – **ExKMC:** [GitHub Repository](https://github.com/navefr/ExKMC)  
  – **ExClus:** [arXiv: Explainable Clustering on Low-dimensional Data Representations](https://arxiv.org/abs/2111.03168)

## Learning Resources
- **Book:**  
  – *Interpretable Machine Learning* by Christoph Molnar

- **Workshops & Conferences:**  
  – Tutorials by experts (e.g., Himabindu Lakkaraju) at conferences such as FAccT.

Happy explaining!